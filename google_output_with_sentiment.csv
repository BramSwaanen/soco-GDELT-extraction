Date,NewsPaper,Headline,MainText,Sentiment_Score,Sentiment_Magnitude
20240522,foxnews,South Korea urges global cooperation for AI development at Seoul summit,"South Korea's science and information technology minister said on Wednesday the world must cooperate to ensure the successful development of AI, as a global summit on the rapidly evolving technology hosted by his country wrapped up. The AI summit in Seoul, which is being co-hosted with Britain, discussed concerns such as job security, copyright and inequality on Wednesday, after 16 tech companies signed a voluntary agreement to develop AI safely a day earlier. A separate pledge was signed on Wednesday by 14 companies including Alphabet's Google, Microsoft, OpenAI and six Korean companies to use methods such as watermarking to help identify AI-generated content, as well as ensure job creation and help for socially vulnerable groups. FOX NEWS AI NEWSLETTER: HOW ARTIFICIAL INTELLIGENCE IS RESHAPING MODERN WARFARE ""Cooperation is not an option, it is a necessity,"" Lee Jong-Ho, South Korea's Minister of Science and ICT (information and communication technologies), said in an interview with Reuters.  ""The Seoul summit has further shaped AI safety talks and added discussions about innovation and inclusivity,"" Lee said, adding he expects discussions at the next summit to include more collaboration on AI safety institutes. The first global AI summit was held in Britain in November, and the next in-person gathering is due to take place in France, likely in 2025. Ministers and officials from multiple countries discussed on Wednesday cooperation between state-backed AI safety institutes to help regulate the technology. CLICK HERE TO GET THE FOX NEWS APP AI experts welcomed the steps made so far to start regulating the technology, though some said rules needed to be enforced. ""We need to move past voluntary... the people affected should be setting the rules via governments,"" said Francine Bennett, Director at the AI-focused Ada Lovelace Institute. AI services should be proven to meet obligatory safety standards before hitting the market, so companies equate safety with profit and stave off any potential public backlash from unexpected harm, said Max Tegmark, President of Future of Life Institute, an organisation vocal about AI systems' risks. South Korean science minister Lee said that laws tended to lag behind the speed of advancement in technologies like AI. ""But for safe use by the public, there needs to be flexible laws and regulations in place.""",0.08399999886751175,4.38100004196167
20240511,foxnews,"Artificial intelligence not always helpful for reducing doctor burnout, studies suggest","The use of generative AI may not be helpful in reducing burnout in health care, new research suggests. Previous research indicated that increased time spent using electronic health record (EHR) systems and handling administrative responsibilities has been a burden on doctors. So some people had heralded artificial intelligence as a potential solution — yet recent investigations by U.S. health systems found that large language models (LLMs) did not simplify clinicians’ day-to-day responsibilities. WHAT IS ARTIFICIAL INTELLIGENCE (AI)? For instance, a 2023 observational study at Brigham and Women’s Hospital in Boston, Massachusetts, examined the impact of using AI for electronic patient messaging. Researchers prompted a large language model to respond to simulated questions from cancer patients — then compared its output to responses from six board-certified radiation oncologists. Medical professionals then edited the AI-generated responses into ""clinically acceptable"" answers to send to patients. The study, published in The Lancet Digital Health, found that the LLM drafts posed ""a risk of severe harm in 11 of 156 survey responses, and death in one survey response."" ""The majority of harmful responses were due to incorrectly determining or conveying the acuity of the scenario and recommended action,"" the researchers wrote. FIRST-EVER AUGMENTED REALITY ABDOMINAL SURGERY PERFORMED IN CHILE: ‘A REVOLUTION’ The researchers concluded that LLM-assisted results (those edited by physicians) displayed a ""best-of-both-worlds scenario"" — reducing physician workload while ensuring that patients get accurate information. ""These early findings … indicate the need to thoroughly evaluate LLMs in their intended clinical contexts, reflecting the precise task and level of human oversight,"" the study concluded. Medical billing codes Another study from New York’s Mount Sinai Health System evaluated four different types of large language models for performance and error patterns when querying medical billing codes. GOOGLE BARD TRANSITIONS TO GEMINI: WHAT TO KNOW ABOUT THE AI UPGRADE The research, published in the journal NEJM AI, found that all tested LLMs performed poorly on medical code querying, ""often generating codes conveying imprecise or fabricated information.""&nbsp; The study concluded, ""LLMs are not appropriate for use on medical coding tasks without additional research."" The study was funded by the AGA Research Foundation and National Institutes of Health (NIH). Researchers noted that although these models can ""approximate the meaning of many codes,"" they also ""display an unacceptable lack of precision and a high propensity for falsifying codes.""&nbsp; ""This has significant implications for billing, clinical decision-making, quality improvement, research and health policy,"" the researchers wrote. Patient messages and physicians' time A third JAMA Network-published study, from the University of California San Diego School of Medicine, evaluated AI-drafted replies to patient messages and physicians' time spent editing them. CHATGPT FOUND BY STUDY TO SPREAD INACCURACIES WHEN ANSWERING MEDICATION QUESTIONS The assumption was that generative AI drafts would lessen a physician's time spent doing these tasks — yet the results showed otherwise. ""Generative AI-drafted replies were associated with significantly increased read time, no change in reply time, significantly increased reply length and [only] some perceived benefits,"" the study found. Researchers suggested that",-0.13899999856948853,6.4029998779296875
20240523,nbcnews,Arizona lawmaker uses ChatGPT to help craft legislation to combat deepfakes,"PHOENIX — A Republican member of the Arizona House used ChatGPT to help craft legislation on artificial intelligence-driven impersonations, which was signed into law by Democratic Gov. Katie Hobbs earlier this week. State Rep. Alex Kolodin used the AI software to help define “digital impersonation” in Arizona’s new law, which aims to regulate deepfake technology. House Bill 2394, which Hobbs signed into law Tuesday, gives Arizona politicians and other residents the ability to get a court order declaring that the person in the deepfake is not them. It comes in the wake of a broader national discussion over digital impersonations. On Monday, actor Scarlett Johansson said that artificial intelligence company OpenAI used an “eerily similar” voice to hers for its new chatbot despite her having declined the company’s request for her to provide her voice. OpenAI announced it would stop using that voice, claiming ""it was never intended to resemble"" Johansson's. Meanwhile, more states are introducing and passing legislation to deal with deepfakes ahead of the 2024 election, amid broad concern over the effect of AI-driven disinformation. “I used it to write the part of the bill that had to do with defining what a deepfake was,” Kolodin said on his use of the software in the legislative process. “I was really struggling with the technical aspects of how to define what a deepfake was. So I thought to myself, ‘Well, why not ask the subject matter expert, ChatGPT?’” Kolodin said. The legislator from Maricopa County said he “uploaded the draft of the bill that I was working on and said, you know, please, please put a subparagraph in with that definition, and it spit out a subparagraph of that definition.” “There’s also a robust process in the Legislature,” Kolodin continued. “If ChatGPT had effed up some of the language or did something that would have been harmful, I would have spotted it, one of the 10 stakeholder groups that worked on or looked at this bill, the ACLU would have spotted, the broadcasters association would have spotted it, it would have got brought out in committee testimony.” But Kolodin said that portion of the bill fared better than other parts that were written by humans. “In fact, the portion of the bill that ChatGPT wrote was probably one of the least amended portions,” he said. He argues that any shortcomings associated with using ChatGPT to write part of a law would also be present if humans take the reins. Kolodin said he didn’t see any pitfalls “that I don’t also see with relying on legislative attorneys to draft up legislation.” Kolodin noted that he used ChatGPT sparingly in the process, employing it for a technical definition of “digital impersonation” while leaning on his experience as a lawyer and politician as well as the legislative process. A representative for the governor’s office confirmed that Hobbs wasn’t aware Kolodin had used ChatGPT to help draft the bill she signed into law. That was an omission Kolodin admits was by design.",-0.06400000303983688,5.313000202178955
20240523,foxnews,Scarlett Johansson AI controversy takes turn as agent says another actress was hired for ChatGPT voice: report,"New revelations from an agent for the actress who voiced ""Sky"" for ChatGPT have thrown a twist into the public dispute between Scarlett Johansson and OpenAI.&nbsp; Johansson, an international superstar known for her roles in ""Avengers"" and ""Her,"" accused the artificial intelligence company of imitating her voice for ChatGPT after she turned down an offer from CEO Sam Altman to be a human voice featured in the AI chatbot's Voice Mode. But the agent for a different actress who landed the role says her client was never asked to imitate Johansson's voice, according to The Washington Post. The actress' agent said neither Johansson nor the 2013 movie ""Her"" — in which Johansson voices a virtual AI assistant — was mentioned when her client auditioned for ChatGPT. The agent also said her client was hired to create the voice for ""Sky"" months before Altman reached out to Johansson, the Post reported. The agent told the Post the name ""Sky"" was chosen to ""signal a cool, airy and pleasant sound,"" the report said. Audio recordings of the actress' voice test sounded identical to the AI-generated SKy voice, the paper reported. SCARLETT JOHANSSON ACCUSES OPEN AI OF PLAGIARIZING VOICE: ‘SHOCKED’ AND ‘IN DISBELIEF’ Johansson released a statement Monday that said Altman contacted her in September about possibly being the voice for ChatGPT. She claimed that he had suggested her ""comforting"" voice ""could bridge the gap between tech companies and creatives"" and help with the ""seismic shift concerning humans and Al."" Though she rejected the offer after ""much consideration and for personal reasons,"" Johansson was furious after several users commented that the ""Sky"" voice system resembled her work in ""Her.""&nbsp; ""When I heard the released demo, I was shocked, angered and in disbelief that Mr. Altman would pursue a voice that sounded so eerily similar to mine that my closest friends and news outlets could not tell the difference. Mr. Altman even insinuated that the similarity was intentional, tweeting a single word ‘her’ - a reference to the film in which I voiced a chat system, Samantha, who forms an intimate relationship with a human,"" the statement read. SNL'S' COLIN JOST FORCED TO CRACK JOKE ABOUT WIFE SCARLETT JOHANSSON'S BODY ON 'WEEKEND UPDATE' Johansson revealed she had hired legal counsel for a potential lawsuit against OpenAI and suggested that her lawyer's demands for an explanation had resulted in OpenAI taking down the ""Sky"" voice on Sunday. In a statement to Fox News Digital, Altman denied that ""Sky"" was intended to resemble Johansson's voice.&nbsp; ""We cast the voice actor behind Sky’s voice before any outreach to Ms. Johansson. Out of respect for Ms. Johansson, we have paused using Sky’s voice in our products. We are sorry to Ms. Johansson that we didn’t communicate better,"" Altman said.&nbsp; SCARLETT JOHANSSON TACKLES AI IN LEGAL SHOWDOWN AGAINST APP THAT USED HER LIKENESS, VOICE IN AD Joanne Jang, a product lead at OpenAi, told The Washington Post that Altman was on a world tour during the casting process",-0.2370000034570694,7.40500020980835
20240523,foxnews,"New Hampshire political consultant behind AI-powered Biden robocalls hit with 24 criminal charges, $6M fine","The New Hampshire political consultant behind robocalls mimicking President Biden is now facing 24 criminal charges, 13 of which are felony counts. Steve Kramer admitted to commissioning robocalls that used artificial intelligence to generate a voice similar to President Biden encouraging recipients not to participate in the primary. The Federal Communications Commission also announced $6 million in fines against Kramer. ""It’s important that you save your vote for the November election,"" the illicit calls stated, according to New Hampshire Attorney General John Formella. The calls added, ""Your vote makes a difference in November, not this Tuesday.""&nbsp; NEW HAMPSHIRE INVESTIGATING FAKE BIDEN ROBOCALL TELLING VOTERS NOT TO PARTICIPATE IN TUESDAY'S PRIMARY  ""After we received multiple reports and complaints on the day these calls were made and the day after these calls were made, my office immediately opened an investigation,"" Formella said. He described how his office's Election Law Unit&nbsp;worked with the Anti-Robocall Multistate Litigation Task Force, a bipartisan task force made up of 50 state attorneys general and the Federal Communications Commission Enforcement Bureau.&nbsp; Kramer previously told local outlet News 9 he produced the phone calls as a stunt to demonstrate the need to regulate AI technology. NEW HAMPSHIRE AG TRACES ROBOCALLS WITH 'AI-GENERATED CLONE' OF BIDEN'S VOICE BACK TO TEXAS-BASED COMPANIES  ""Maybe I’m a villain today, but I think, in the end, we get a better country and better democracy because of what I’ve done, deliberately,"" Kramer previously said of the investigation. The New Hampshire robocalls sparked immediate action in outlawing deep fakes impersonating political candidates. The FCC ruled the practice illegal in February.&nbsp; CLICK HERE TO GET THE FOX NEWS APP&nbsp;  With the unanimous adoption of a ruling that recognizes calls made with AI-generated voices as ""artificial"" under the Telephone Consumer Protection Act (TCPA), a 1991 law restricting junk calls that use artificial and prerecorded voice messages, the FCC said it was giving state attorneys general new tools to go after those responsible for voice-cloning scams.&nbsp; WHAT IS ARTIFICIAL INTELLIGENCE (AI)? ""Bad actors are using AI-generated voices in unsolicited robocalls to extort vulnerable family members, imitate celebrities and misinform voters. We’re putting the fraudsters behind these robocalls on notice,"" FCC Chairwoman Jessica Rosenworcel said in a statement. ""State Attorneys General will now have new tools to crack down on these scams and ensure the public is protected from fraud and misinformation."" Fox News' Danielle Wallace and The Associated Press contributed to this report.",-0.1860000044107437,6.789999961853027
20240513,foxnews,Air Force AI dogfight means tech could replace Maverick vs. China,"Fulfilling a bold promise to the Senate, Secretary of the Air Force Frank Kendall put himself in the cockpit and let AI take over and fly an F-16 through an hour of aerial engagements and dogfights near Edwards Air Force Base, California. &nbsp; There’s just one reason Kendall, age 74, a West Point graduate and career Army officer, took that flight.&nbsp; Deterring China. America’s top priority right now is to make sure the U.S., not China, leads in AI. The U.S. Air Force just took a big step in the right direction. &nbsp; CHINA COULD 'OVERWHELM' US MILITARY BASES AS BIDEN SHOWS 'ALARMING LACK OF URGENCY': HOUSE COMMITTEE CHAIR Not that it wasn’t fun. Judging from the big smile on Kendall’s face, it was a heck of a flight. &nbsp; To be clear, the highly modified F-16 known as the X-62 Vista was a two-seat version with a highly experienced pilot in the back seat. The take-off and landing were hand-flown. &nbsp; Kendall in the Vista F-16 flew to the restricted airspace training ranges east of Bakersfield and west of the Nevada border. There, pilots can go supersonic, carry out simulated bombing runs, and of course, dogfight. Once the exercise began, another F-16 playing the opponent would try to gain position advantage on the Vista. Kendall and the backseat pilot were basically spectators, watching cockpit instruments as the AI agents gave the control inputs and made the tactical decisions. &nbsp; ""We turn the automation on and let it control the airplane for some period of time,"" Kendall said, for ""a minute or two. Then you turn it back off.""&nbsp; Just let me add, a minute or two is an eternity in air combat. Korean War jet aces like Capt. Joseph McConnell shot down multiple enemy MiGs in seconds. &nbsp; While the AI was flying, the horizon tilted back and forth as it fought. The F-16 bubble canopy gives almost a 360-degree view and good visibility under the plane. Kendall got quite a view.&nbsp; I’m impressed that Kendall was keen to let an AI agent yank and bank him through combat maneuvers pulling five times the force of gravity. In my experience in one F-16 wargame flight in Alaska, you can take the G force loads as they bear down and scrunch your body as the plane turns fast. It’s the unloading of Gs that gives you the out-of-control, freefall feeling. &nbsp; Of course, pulling up to 9Gs is just another day at the office for F-16 test pilots. They maneuver to win; it’s dramatic, but it’s basically a tactic. Kendall’s flight suggests the days of pulling Gs are coming to a close. &nbsp; This was no spontaneous joyride. Granted, America’s top fighters already have a lot of automation in their flight controls and tactical systems. The F-16 was born fly-by-wire; it’s actually slightly unstable in flight without computer guidance. &nbsp; This special F-16 has been flying AI test sorties since late 2022. A rectangular component behind the cockpit contains",0.22300000488758087,12.784000396728516
20240502,foxnews,AI expert: ChatGPT prompts you’ll wish you knew sooner,"ChatGPT has changed my life — and yours, even if you don’t use it as much as I do. You’ve probably noticed the new AI search bar in all the Meta apps, including Facebook and Instagram. It won’t be long before all your most-used apps and services integrate chatbots. (Yes, I’m sure the folks at Google are quaking in their search boots.) Win an iPhone 15 worth $799! I'm giving one away to someone who tries my free daily tech newsletter.&nbsp;Enter to win now while you’re thinking about it. WHAT IS CHATGPT? Don’t wait to get comfortable with AI. Try out a few of these prompts and flex your chatbot muscles. You’ll see just how easy they are to use. To save you time Recently, I uploaded a commercial building's rent roll, profit and loss statement, and comps for the area. I asked ChatGPT to analyze the data and see if it’s a good investment. Sure, I know how to do that math myself, but it would have taken 30 minutes. No joke, it took me longer to upload the documents than it did for ChatGPT to come up with the answers — about 30 seconds. The best part is it laid out the calculations and reasoning, so I could analyze them myself and double-check its work. If you don’t get that with your answer, you can always ask something like, ""How did you make that decision?"" or ""Tell me how you got that answer."" To make a decision when you can’t There’s a term for this: Decision fatigue. Sometimes, you’ve had to pick so many things in one week that you just can’t do it again. Try these: To help you do something complex Say you’re an HR manager and must create an employee guide from scratch. That’s a heck of a lot of work, and you’d likely end up heading to a search engine to see where to begin. A chatbot can do that, too, and even create an outline for you.&nbsp; MORE DOCTORS USE CHATGPT TO HELP WITH BUSY WORKLOADS, BUT IS AI A RELIABLE ASSISTANT? This bears emphasis: Do not use an LLM chatbot to create legal documents or anything that really needs a lawyer or other professional’s touch. But as a starting place? Absolutely. To be an impartial third party You're arguing with a friend, your spouse, or a relative. Or maybe you're in a contentious situation with someone professionally. Before you text or type an angry reply, consult someone without emotion attached to the situation: your chatbot of choice. Here’s a prompt idea: ""My roommate and I are arguing because she keeps leaving her dirty dishes in the sink for days, even though they’re attracting bugs. How can I respectfully make the point that I need her to stop this?"" To analyze information This is an AI sweet spot. The technology excels at finding patterns and pointing them out. Here are a couple of examples to get started: ""Here’s a 20-page legal document.",0.10300000011920929,16.565000534057617
20240518,foxnews,Fox News AI Newsletter: How artificial intelligence is reshaping modern warfare,"Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements. IN TODAY’S NEWSLETTER: - How artificial intelligence is reshaping modern warfare- Sebastian Maniscalco admits AI makes a guy who writes like ‘Rocky Balboa’ sound like he ‘went to Yale’- Researchers create AI-powered sarcasm detector NEXT-GEN BATTLE: Modern warfare is changing rapidly, and harnessing artificial intelligence is key to staying ahead of America’s adversaries.  TECHNICALLY SPEAKING: Comedian Sebastian Maniscalco isn’t sure what to make of artificial intelligence in the industry.&nbsp; FUNNY BOT: A team of university researchers in the Netherlands says they've developed an artificial intelligence (AI) platform that can recognize sarcasm, according to a new report.  'OUTCOMPETE CHINA': A bipartisan group of U.S. senators on Wednesday joined in a call to boost American funding of artificial intelligence research. 'MACHINE LEARNING': The widespread use of artificial intelligence tools has many workers concerned that the rapidly-evolving technology will eventually result in them losing their job, and one expert says that is a real concern — but not in the way some might expect.  AI AT WAR: The world may end up breaking into tech alliances as a guiding political issue in the years to come, according to a retired American serviceman-turned-novelist as detailed in his new book.&nbsp; Subscribe now to get the Fox News Artificial Intelligence Newsletter in your inbox. FOLLOW FOX NEWS ON SOCIAL MEDIA FacebookInstagramYouTubeTwitterLinkedIn SIGN UP FOR OUR OTHER NEWSLETTERS Fox News FirstFox News OpinionFox News LifestyleFox News Health DOWNLOAD OUR APPS Fox NewsFox BusinessFox WeatherFox SportsTubi WATCH FOX NEWS ONLINE Fox News Go STREAM FOX NATION Fox Nation Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with&nbsp;Fox News here.",0.07100000232458115,3.578000068664551
20240430,cnn,Samsung reports enormous jump in profit on AI boom,"Samsung Electronics forecast demand for artificial intelligence would hold strong and tighten supply of some high-end chips, joining rivals in benefiting from a solid rebound in the battered global memory chip market. The upbeat outlook from the world’s largest memory chip maker sent its shares 1.8% higher on Tuesday after it reported a more than 10-fold rise in first-quarter operating profit. But so far this year Samsung shares are down 0.8%, lagging SK Hynix’s 24% gain, as it seeks to catch up with its smaller rival in the supply of top-end chips such as high bandwidth memory (HBM) to AI leader Nvidia (NVDA). “We plan to increase supply of HBM-related chips in 2024 by more than three-fold versus last year,” Jaejune Kim, a Samsung vice president in charge of the memory division, said on an earnings call. Samsung said it began mass production this month of the latest HBM chips for use in generative AI chipsets, called 8-layer HBM3E. It is seeking to capitalize on the AI boom that has benefited SK Hynix, which had been the sole supplier of HBM3 chips to Nvidia. Samsung said it planned to start making the 12-layer version during the second quarter, and expected the latest HBM3E products to account for two-thirds of its HBM output by year-end. Analysts said the targets were aggressive. Samsung’s 8-layer HBM3E appears to be supplying Nvidia, while the 12-layer may go to AMD (AMD) and Nvidia, said Jeff Kim, head of research at KB Securities. “As Samsung’s technology is advantageous for high-stacking, while SK Hynix has its advantages in the 8-layer, there may be a segmentation where Nvidia gets 12-layer products from Samsung and most 8-layer products from SK Hynix,” Kim said. “Samsung is working hard to improve the yield of its 12-layer product,” he added. Samsung did not respond immediately to a request for comment on its HBM customers. Samsung also said it will step up offerings of high-end solid-state drive (SSD) products to meet AI server demand, and expected high-end memory chip supply to become tighter toward year-end due to capacity being focused on HBM, echoing comments from SK Hynix last week. Jump in operating profit The South Korean company’s first-quarter revenue rose 13% to 71.9 trillion won ($52.14 billion), including a 96% increase in memory chip revenue to 17.49 trillion won as prices rose steeply from a severe downturn, partly thanks to the boom in AI. Operating profit rose to 6.6 trillion won in January to March, up from 640 billion won a year earlier. It was the company’s highest operating profit since the third quarter of 2022. The chip division, historically Samsung’s cash cow business that used to account for two-thirds of its operating profit, swung to a profit of 1.91 trillion won in the March quarter from a 4.58 trillion won loss a year earlier. It was the first profit since the third quarter of 2022. Prices of NAND flash chips used to store data increased by 23% to 28% during the",0.27300000190734863,8.055000305175781
20240430,cbsnews,"Chicago Tribune, other major newspapers accuse artificial intelligence companies of stealing content","A group of major newspaper publishers, including the Chicago Tribune and New York Daily News, are accusing two of the biggest artificial intelligence companies of stealing their content to improve their products.That accusation comes in a civil lawsuit filed in the U.S. District Court in New York. The lawsuit targets two of the biggest generative AI platforms in the world, Open AI, the creators of ChatGPT, and Microsoft's Copilot AI program. What is AI's threat to local news? The plaintiffs argue that the development of the internet and the theft of their content is the biggest threat to local news.The suit claims Open AI and Microsoft pay for computers, technical infrastructure, programmers, and other tech workers but not for the newspapers' information used to train their models to generate the content they create. ""Despite admitting that they need copyrighted content to produce a commercially viable GenAI product, the defendants contend they can fuel the creation and operation of these products with the Publishers' content without permission or paying for the privilege.""They are wrong on both counts.""Examples of AI allegedly stealing contentThe lawsuit cited several examples of ChatGPT and Copilot returning verbatim articles from the Chicago Tribune and other publications in response to a user's question on the platform. The newspaper publishers want the companies to compensate them for ""their unlawful use of protected newspaper content to date.""The lawsuit seeks unspecified statutory damages, compensatory damages, and restitution. Artificial intelligence has been touted for various uses, from helping fight wildfires to filling a shortage of mental health professionals.However, it also has been known to serve up wildly inaccurate information about elections.The Associated Press reported that Microsoft declined to comment Tuesday. OpenAI didn't immediately respond to a request for comment to the AP.In addition to the Tribune and Daily News, the other publishers named as plaintiffs are The Orlando Sentinel, South Florida Sun-Sentinel, San Jose Mercury-News, DP Media Network, ORB Publishing, and Northwest Publications.",-0.3970000147819519,7.051000118255615
20240602,foxnews,DOJ claims it can't release Biden-Hur interview due to threat of AI deepfakes,"The Justice Department cannot release audio from President Biden's interview with Special Counsel Robert Hur due to the threat of potential deepfakes, the DOJ argued in a Friday court filing. The filing came as part of a legal challenge against Biden's efforts to exercise executive privilege over the recording to keep it from the public. The DOJ acknowledged in its Friday filing that there is already enough public audio available to create AI deepfakes of both Biden and Hur, but it said releasing the true recording would make it more difficult to disprove any false versions. ""The passage of time and advancements in audio, artificial intelligence, and ‘deep fake’ technologies only amplify concerns about malicious manipulation of audio files. If the audio recording is released here, it is easy to foresee that it could be improperly altered, and that the altered file could be passed off as an authentic recording and widely distributed,"" the department wrote. Associate Deputy Attorney General Bradley Weinsheimer wrote in the filing that releasing the tape would ""make it far more likely that malicious actors could pass off a deepfake as the authentic recording."" BIDEN ASSERTS EXECUTIVE PRIVILEGE OVER RECORDINGS FROM CLASSIFIED DOCUMENTS PROBE Biden's administration is facing a myriad of efforts from conservative legal groups and House Republicans to force the release of the audio. The DOJ has already released a transcript of the interview, which revealed multiple embarrassing moments for the president. BIDEN, NOT SPECIAL COUNSEL HUR, BROUGHT UP SON'S DEATH IN QUESTIONING Biden met with Hur for about five hours last year, when he was grilled about his handling of the classified documents. Hur's report, released earlier this year, declared Biden to be a forgetful, but well-meaning elderly man. The report highlighted several instances where Biden could not recall key details about his life, including when he served as vice president and the year of his son Beau Biden's death. Biden was outraged at the report and subsequently got caught in a number of false statements regarding his interview. For instance, he claimed that Hur brought up the topic of Beau's death, despite the transcript showing that Biden had broached the topic. HUNTER BIDEN IS IN COURT IN DELAWARE. HERE'S WHAT HE DOESN'T WANT THE JURY TO HEAR ""President Biden is apparently afraid for the citizens of this country and everyone to hear those tapes,"" House Speaker Mike Johnson, R-La., said after Biden exerted privilege over the recording. ""They obviously confirm what the special counsel has found, and would likely cause, I suppose, in his estimation, such alarm with the American people that the president is using all of his power to suppress their release."" CLICK HERE TO GET THE FOX NEWS APP Some Republicans have speculated that the transcript of the interview may not line up with the audio, saying it may have been edited to prevent embarrassing Biden. Weinsheimer rejected those claims in Friday's filing, saying only minor adjustments were made to the transcript, such as removing repeated words and",-0.5659999847412109,10.503000259399414
20240524,cnn,Privacy experts sound the alarm over Microsoft’s latest AI tool,"Microsoft’s buzziest new AI feature is raising concerns that it could potentially be misused in the wrong hands. This week, the company showed off a new tool called Recall for Windows computers that acts as a personal “time machine,” allowing users to quickly pull up anything that’s ever been on screen, such as documents, images and websites. It’s different from a keyword search; the tool regularly saves screenshots of the user’s screen and stores them directly on the device. It then uses AI to process the data and make it searchable. For example, if someone previously searched for a green dress or the name of a local ice cream shop, they can ask the feature to “recall” anything in their history that was shown on screen. Although so-called semantic search is a big step forward for AI, it comes at a time when the industry is moving so quickly and government regulators, companies and consumers are still figuring out how to use the technology responsibly. Jen Golbeck – a professor of AI at the University of Maryland who focuses on privacy – said the recall feature could pose a potential “nightmare” if the device falls into the wrong hands. “Stuff may stay on your device, but that doesn’t mean people can’t get to it,” she said. “You won’t have an option to protect yourself even if you use incognito mode or clear your history because the tool has access to everything that’s been on your screen.” The UK’s independent regulator for Data Protection and Freedom of Information, the Information Commissioner’s Office (ICO), told CNN it is investigating the tool “to understand the safeguards in place to protect user privacy.” “We expect organisations to be transparent with users about how their data is being used and only process personal data to the extent that it is necessary to achieve a specific purpose,” the ICO said in a statement. Microsoft did not immediately respond to a request for comment. CEO Satya Nadella told The Wall Street Journal in an interview ahead of Monday’s launch that web searches must only be done on Microsoft’s Edge web browser and that the screenshots never leave the user’s computer. “You have to put two things together: This is my computer and this is my Recall – and it’s all being done locally,” he said. Geoff Blaber, CEO of market research firm CCS Insight, said that makes the issue less concerning. “The backlash by some to this feature isn’t surprising, but it’s an overreaction given that the data stays exclusively on the device and the user has full control,” Blaber said. Someone can decide whether to turn the feature on during the device setup process and can customize and blacklist which apps and websites Recall can access. “These controls suggest the feature has been built with security and privacy at its core,” he said. “Recall won’t appeal to everyone but the utility provided is likely to be significant.” Potential for malicious uses But Golbeck cited times",-0.024000000208616257,7.290999889373779
20240524,cnn,FCC is considering AI rules for political ads,"The Federal Communications Commission is taking initial steps toward new rules that could require political ads on TV and radio to include disclaimers about the use of artificial intelligence. On Wednesday, FCC Chairwoman Jessica Rosenworcel called on other agency commissioners to support such regulations amid growing fears that AI-generated deepfakes could disrupt elections. “As artificial intelligence tools become more accessible, the Commission wants to make sure consumers are fully informed when the technology is used,” Rosenworcel said in a news release. “Today, I’ve shared with my colleagues a proposal that makes clear consumers have a right to know when AI tools are being used in the political ads they see, and I hope they swiftly act on this issue.” Wednesday’s proposal aims to open a rulemaking process at the FCC that would likely take months to play out. The proposal calls for new rules governing broadcast TV and radio, as well as cable and satellite providers. Under the proposed rules, political advertisers on those mediums would have to make on-air disclosures if their ads contain AI-generated content. The FCC does not regulate internet-based media such as streaming video services or social media. As part of the proposed rule, political advertisers would also have to provide written disclosures in the files that broadcasters are required to make available to the public. The FCC move seeks to fill a yawning gap in the regulation of artificial intelligence in political advertising. Existing US election law prohibits campaigns from “fraudulently misrepresenting other candidates or political parties,” but whether this prohibition extends to AI-generated content is an open question. Last summer, Republicans on the Federal Election Commission blocked a move that could have made clear the law extended to AI-created depictions; the FEC has since agreed to revive the discussion, but it has not reached a decision on the matter. In the meantime, some US lawmakers have proposed legislation that could clamp down on AI in elections. In March, a bipartisan proposal by Minnesota Democratic Sen. Amy Klobuchar and Alaska Republican Sen. Lisa Murkowski unveiled the AI Transparency in Elections Act, which could require AI disclaimers on political ads. Senate Majority Leader Chuck Schumer, a Democrat from New York, has stressed the urgent need for Congress to create guardrails for artificial intelligence, particularly for elections. Last week, he and a bipartisan group of senators released a blueprint for legislative action. But many policy analysts doubt that Congress can pass meaningful AI legislation during an election year. Online platforms such as Meta have taken their own steps to address AI in political ads, requiring campaigns to disclose the use of deepfakes and banning the use of its in-house generative AI tools for political advertising.",-0.050999999046325684,3.9719998836517334
20240524,cnn,Google Search’s AI falsely said Obama is a Muslim. Now it’s turning off some results,"Google promised its new artificial intelligence search tools would “do the work for you” and make finding information online quicker and easier. But just days after the launch, the company is already walking back some factually incorrect results. Google earlier this month introduced an AI-generated search results overview tool, which summarizes search results so that users don’t have to click through multiple links to get quick answers to their questions. But the feature came under fire this week after it provided false or misleading information to some users’ questions. For example, several users posted on X that Google’s AI summary said that former President Barack Obama is a Muslim, a common misconception. In fact, Obama is a Christian. Another user posted that a Google AI summary said that “none of Africa’s 54 recognized countries start with the letter ‘K’” — clearly forgetting Kenya. Google confirmed to CNN on Friday that the AI overviews for both queries had been removed for violating the company’s policies. “The vast majority of AI Overviews provide high quality information, with links to dig deeper on the web,” Google spokesperson Colette Garcia said in a statement, adding that some other viral examples of Google AI flubs appear to have been manipulated images. “We conducted extensive testing before launching this new experience, and as with other features we’ve launched in Search, we appreciate the feedback. We’re taking swift action where appropriate under our content policies.” The bottom of each Google AI search overview acknowledges that “generative AI is experimental.” And the company says it conducts testing designed to imitate potential bad actors in an effort to prevent false or low-quality results from showing up in AI summaries. Google’s search overviews are part of the company’s larger push to incorporate its Gemini AI technology across all of its products as it attempts to keep up in the AI arms race with rivals like OpenAI and Meta. But this week’s debacle shows the risk that adding AI – which has a tendency to confidently state false information – could undermine Google’s reputation as the trusted source to search for information online. Even on less serious searches, Google’s AI overview appears to sometimes provide wrong or confusing information. In one test, CNN asked Google, “how much sodium is in pickle juice.” The AI overview responded that an 8 fluid ounce-serving of pickle juice contains 342 milligrams of sodium but that a serving less than half the size (3 fluid ounces) contained more than double the sodium (690 milligrams). (Best Maid pickle juice, for sale at Walmart, lists 250 milligrams of sodium in just 1 ounce.) CNN also searched: “data used for google ai training.” In its response, the AI overview acknowledged that “it’s unclear if Google prevents copyrighted materials from being included” in the online data scraped to train its AI models, referencing a major concern about how AI firms operate. It’s not the first time Google has had to walk back the capabilities of its AI tools over",-0.22499999403953552,10.413999557495117
20240524,nbcnews,Google’s AI faces social media mockery after viral errors,"Social media has been buzzing with examples of Google’s new, “experimental” artificial intelligence tool going awry. The feature, which writes an “AI overview” response to user queries based on sources pulled from around the web, has been placed at the top of some search results. But repeatedly, social media posts show that the tool is delivering wrong or misleading results. An NBC News review of answers provided by the tool showed that it sometimes displays false information in response to simple queries. NBC News was easily able to reproduce several results highlighted in viral posts online, and found other original examples in which Google’s AI tool provided incorrect information. For example, an NBC News search for “how many feet does an elephant have” resulted in a Google AI overview answer that said “Elephants have two feet, with five toes on the front feet and four on the back feet.” Some of the false answers verged into politically incorrect territory. An NBC News search for “how many muslim presidents in us,” the results of which were first posted on social media, returned a Google AI overview that said “Barack Hussein Obama is considered the first Muslim president of the United States.” Obama, however, is a Christian. Google said this overview example violated its policies and that it would be “taking action.” “The examples we’ve seen are generally very uncommon queries, and aren’t representative of most people’s experience using Search,” a Google spokesperson said in a statement. “The vast majority of AI Overviews provide high quality information, with links to dig deeper on the web,"" the spokesperson continued. ""We conducted extensive testing before launching this new experience to ensure AI overviews meet our high bar for quality. Where there have been violations of our policies, we’ve taken action — and we’re also using these isolated examples as we continue to refine our systems overall.” It’s difficult to assess how often false answers are being served to users. The responses are constantly shifting, and on social media, it’s difficult to tell what is real or fake. Some Google users have created workarounds to avoid the new AI Overview feature altogether. Ernie Smith, a writer and journalist, quickly built a website that reroutes Google searches through its historical “Web” results function, which avoids the AI Overview or other information boxes that prioritize some results over others. Adding “udm=14” to Google search URLs strips the new feature from results. Smith told NBC News that his new website has quickly gained traction on social media, surpassing the traffic of his entire decade-old blog in just one day. “I think people are generally frustrated with the experience of Google right now,” Smith said in a phone interview. “In general, the average person doesn’t feel like they have a lot of agency.” A Google spokesperson said the company believes users are deliberately attempting to trip up the technology with uncommon questions. Some deeper dives into why the answers have gone awry suggest that the tool is pulling",-0.2759999930858612,11.871000289916992
20240531,foxnews,Luxury wedding planner reveals how engaged couples are using AI on their big day,"As artificial intelligence grows in popularity, the latest tech tools are creeping into just about every industry and endeavor — including wedding planning. A luxury wedding planner this spring shared how brides and grooms are making use of sophisticated AI tools to ease the stress of their big day.&nbsp; Lisa Lafferty, a wedding and event planner in Beverly Hills, California, said she's helped throw some extravagant parties in her decade of experience — which has given her an up-close look at AI's use in the wedding space. WEDDING PLANNING COMPANY LAUNCHES AI TOOL TO HELP COUPLES ‘SPLIT THE DECISIONS’ FOR THEIR SPECIAL DAY Owner of Beverly Hills Premier Catering, Lafferty expanded her catering business to event planning in 2018 and has since planned events for celebrities, real estate moguls, Fortune 500 brands and more, she said.&nbsp; Here are three surprising insights into how AI is being used in the wedding industry today. 3 ways couples are using AI at weddings 1. For writing their vows Lafferty said many couples are tapping into artificial intelligence tools to support their vows spoken on the big day. HOW TRAVELERS ARE USING CHATGPT TO PLAN TRIPS ON A BUDGET ""Not everyone feels like they can communicate their emotions and what they want to say in a way that feels natural, authentic, comfortable and appropriately concise,"" she said.&nbsp; ""Because of this, many couples are using ChatGPT to write their vows,"" said Lafferty. They're ""putting the main ideas into the platform and then using what it provides as a basis to work from."" AI TOOL HELPS COUPLES WRITE WEDDING VOWS AS MARRIAGE EXPERT WARNS, ‘BE CAUTIOUS’ WITH TECHNOLOGY This can help couples if they're suffering from a bout of writer’s block, said the wedding planner. 2. For making announcements Using AI as a free DJ is also a popular trend among newlyweds on their wedding day.&nbsp; Many couples will use an artificial intelligence voice generator to make announcements at their wedding, said Lafferty. UNIQUE RECEPTION FOOD ITEMS THAT WILL TAKE YOUR WEDDING TO THE NEXT LEVEL&nbsp; The announcements might tell guests it’s time to be seated for dinner, for example.&nbsp; ""This is especially common at smaller weddings,"" said Lafferty, ""where there isn’t a DJ or large band with an emcee, and in cases where there isn’t a member of the clergy leading the ceremony."" Although it might seem odd at first, Lafferty said it’s much more common in today’s wedding agendas than many people may realize. 3. For remembering or honoring loved ones Using artificial intelligence to bring since-departed loved ones ""to"" the wedding day — or people who simply can't get there physically — is also becoming more popular, she said. CLICK HERE TO SIGN UP FOR OUR LIFESTYLE NEWSLETTER AI is being used to create a visual edit or a voice generation of a loved one who has passed, or a beloved family member or friend who can't be present physically. ""Whether it's relatives who have passed or people who simply can’t make",0.24799999594688416,6.275000095367432
20240521,cbsnews,"Generative AI poses threat to election security, federal intelligence agencies warn","Generative artificial intelligence could threaten election security this November, intelligence agencies warned in a new federal bulletin.Generative AI uses images, audio, video and code to create new content, like so-called ""deep fake"" videos in which a person is made to look like they're saying something they never said. Both foreign and domestic actors could harness the technology to create serious challenges heading into the 2024 election cycle, according to the analysis compiled by the Department of Homeland Security and sent to law enforcement partners nationwide. Federal bulletins are infrequent messages to law enforcement partners, meant to call attention to specific threats and concerns. ""A variety of threat actors will likely attempt to use generative artificial intelligence (AI) - augmented media to influence and sow discord during the 2024 U.S. election cycle, and AI tools could potentially be used to boost efforts to disrupt the elections,"" the bulletin, shared with CBS News, stated. ""As the 2024 election cycle progresses, generative AI tools likely provide both domestic and foreign threat actors with enhanced opportunities for interference by aggravating emergent events, disrupting election processes, or attacking election infrastructure.""Russia seeks to undermine election integrity worldwide, U.S. assessment saysDirector of National Intelligence Avril Haines also warned Congress about the perils of generative AI during a Senate Intelligence Committee hearing last week, saying AI technology can create realistic ""deepfakes"" whose origin can be concealed. ""Innovations in AI have enabled foreign influence actors to produce seemingly authentic and tailored messaging more efficiently, at greater scale,"" she testified, while insisting the U.S. is better prepared for an election than ever. One example the DHS cited in the bulletin was a fake robocall impersonating the voice of President Joe Biden on the eve of the New Hampshire primary in January. The fake audio message was circulated, encouraging recipients of the call to ""save your vote"" for the November general election instead of participating in the state's primary. The ""timing of election-specific AI-generated media can be just as critical as the content itself, as it may take time to counter-message or debunk the false content permeating online,"" the bulletin said. The memo also noted the lingering threat overseas, adding that in November 2023, an AI video encouraged a southern Indian state to vote for a specific candidate on election day, giving officials no time to discredit the video.AI chatbots are serving up wildly inaccurate election information, new study says The bulletin goes on to warn about the potential use of artificial intelligence to target election infrastructure. ""Generative AI could also be leveraged to augment attack plotting if a threat actor, namely a violent extremist, sought to target U.S. election symbols or critical infrastructure,"" the bulletin read. ""This may include helping to understand U.S. elections and associated infrastructure, scanning internet-facing election infrastructure for potential vulnerabilities, identifying and aggregating a list of election targets or events, and providing new or improved tactical guidance for an attack.""Some violent extremists have even experimented with AI chatbots to fill gaps in tactical and weapons",-0.39899998903274536,7.146999835968018
20240529,foxnews,Fox News AI Newsletter: Musk's AI prediction,"Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements. IN TODAY’S NEWSLETTER: - Elon Musk expects AI will replace all human jobs, lead to 'universal high income'- FCC’s proposal to regulate AI in political ads is misguided, commissioner says- Indian military ramps up AI capabilities in effort to keep up with regional powers  SHOW ME THE MONEY: Billionaire entrepreneur Elon Musk reiterated his stance this week that artificial intelligence will eventually eliminate the need for humans to work, giving his vision for how the future will look as the technology continues to rapidly advance. AI IN POLITICAL ADS: The Federal Communications Commission last week proposed a new regulation that would require the use of artificial intelligence in political advertisements to be disclosed, which has one commissioner slamming the move as regulatory overreach ahead of the election.  HI-TECH WAR PLANNING: India, a country blessed with a strong high-tech industry, is applying its brains not just to commercial artificial intelligence but also to its military, as its neighbor and regional rival China continues to pour billions into AI research. CASH INFLUX: Billionaire Elon Musk's artificial intelligence startup xAI announced Sunday that the company raised $6 billion in Series B funding that lifts the company's valuation to $24 billion after the investment.  DON’T BE DUPED: Advanced artificial intelligence scams are lurking behind innocuous search engine queries, leveraging what's known as ""search engine optimization"" to deceive users, according to expert advice from GuidePoint Security, highlighting how cybercriminals manipulate these systems. Subscribe now to get the Fox News Artificial Intelligence Newsletter in your inbox. FOLLOW FOX NEWS ON SOCIAL MEDIA FacebookInstagramYouTubeTwitterLinkedIn SIGN UP FOR OUR OTHER NEWSLETTERS Fox News FirstFox News OpinionFox News LifestyleFox News Health DOWNLOAD OUR APPS Fox NewsFox BusinessFox WeatherFox SportsTubi WATCH FOX NEWS ONLINE Fox News Go STREAM FOX NATION Fox Nation Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News&nbsp;here.",0.026000000536441803,3.5850000381469727
20240504,foxnews,Fox News AI Newsletter: Emily Blunt's AI admission,"Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements. IN TODAY’S NEWSLETTER: - Emily Blunt admits new technology is ‘something we’re all nervous about’- AI expert: ChatGPT prompts you’ll wish you knew sooner- State Department wants China, Russia to declare that AI won't control nuclear weapons, only humans ‘HUGE CONCERNS’: Emily Blunt and Ryan Gosling hope audiences will continue to appreciate the people who make movies happen behind the scenes as artificial intelligence continues to infiltrate the industry.  BEST CHATGPT PROMPTS: You’ve probably noticed the new AI search bar in all the Meta apps, including Facebook and Instagram. It won’t be long before all your most-used apps and services integrate chatbots.  STANDING VIGILANT: A State Department official is pushing Thursday for&nbsp;China and Russia to declare that only humans – and not artificial intelligence – will make decisions on deploying nuclear weapons.&nbsp; SUPERHUMAN POWER: Imagine stepping into the wilderness, not just as an adventurer, but as a superhuman explorer. That’s exactly what the X1 all-terrain exoskeleton offers.  Subscribe now to get the Fox News Artificial Intelligence Newsletter in your inbox. FOLLOW FOX NEWS ON SOCIAL MEDIA FacebookInstagramYouTubeTwitterLinkedIn SIGN UP FOR OUR OTHER NEWSLETTERS Fox News FirstFox News OpinionFox News LifestyleFox News Health DOWNLOAD OUR APPS Fox NewsFox BusinessFox WeatherFox SportsTubi WATCH FOX NEWS ONLINE Fox News Go STREAM FOX NATION Fox Nation Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News&nbsp;here.",0.20600000023841858,3.1570000648498535
20240510,foxnews,Fox News AI Newsletter: American spies to use secret AI service from Microsoft: report,"Welcome to Fox News’ Artificial Intelligence newsletter with the latest AI technology advancements. IN TODAY’S NEWSLETTER: - US spies to use secretive AI service from Microsoft- Sheryl Crow demands lawmakers 'act now' on AI, after her fears inspired new album- US blocks some Intel, Qualcomm exports to China over Beijing's objections ‘AI FOR SPIES’: U.S. intelligence agencies will soon be using a secretive generative artificial intelligence (AI) platform from Microsoft that will let America's spies safely use AI models in the process of analyzing sensitive data.  'ACT NOW': Sheryl Crow is calling on Congress to ""act now"" about artificial intelligence in the music industry and beyond. CHIP RESTRICTIONS: The U.S. on Tuesday revoked some of Intel and Qualcomm's licenses to export to China over national security concerns, a move that the Chinese government complained was unnecessary and excessive.  DOWN LOW: The use of generative artificial intelligence tools by employees in the workplace is booming, but most of the workers who are utilizing the new technology have reservations about admitting it, new data indicates. LAPTOP KILLER: Apple just made its first artificial intelligence product move with the M4 Apple silicon chip in an iPad pro model that is bigger, faster, thinner and lighter than its predecessor.&nbsp; &nbsp;&nbsp;  Subscribe now to get the Fox News Artificial Intelligence Newsletter in your inbox. FOLLOW FOX NEWS ON SOCIAL MEDIA FacebookInstagramYouTubeTwitterLinkedIn SIGN UP FOR OUR OTHER NEWSLETTERS Fox News FirstFox News OpinionFox News LifestyleFox News Health DOWNLOAD OUR APPS Fox NewsFox BusinessFox WeatherFox SportsTubi WATCH FOX NEWS ONLINE Fox News Go STREAM FOX NATION Fox Nation Stay up to date on the latest AI technology advancements and learn about the challenges and opportunities AI presents now and for the future with Fox News&nbsp;here.",0.03999999910593033,3.5859999656677246
20240515,cnn,Chuck Schumer and bipartisan group of senators unveil plan to control AI – while investing billions of dollars in it,"Federal legislation to govern artificial intelligence took another step closer to reality on Wednesday as Senate Majority Leader Chuck Schumer, along with a bipartisan trio of senators, announced a sprawling blueprint to shape how congressional committees tackle the technology in forthcoming bills. The 31-page roadmap released this week calls for billions of dollars in government spending to accelerate AI research and development, reflecting earlier commitments by Schumer, a Democrat from New York, and the so-called “AI gang” to prioritize US innovation in an intensely competitive field. It also instructs multiple Senate committees to come up with guardrails for AI to address some of its biggest risks, such as AI-enabled discrimination, job displacement and election interference. “Harnessing the potential of AI demands an all-hands-on-deck approach and that’s exactly what our bipartisan AI working group has been leading,” Schumer said Wednesday. Some of the document’s proposals reflect longstanding congressional goals, such as the creation of a national data privacy law that gives consumers more control over their personal information and which could help regulate AI companies’ use of such data. Others appear modeled after legislation adopted by the European Union, such as a proposed ban on the use of AI for social scoring systems akin to those implemented by the Chinese government. And it urges congressional committees to develop coherent policies for when and how to impose export controls on “powerful AI systems” — or for designating certain AI models as classified for national security purposes. The roadmap endorses a recommendation to allocate at least $32 billion a year, or at least 1% of US GDP, on AI research and development, a proposal issued in a 2021 report by the National Security Commission on Artificial Intelligence. The organizing plan developed over months of meetings and listening sessions with top tech companies, civil rights leaders, labor unions and intellectual property holders. And it seeks to reinvigorate a legislative push that began last year, after Schumer took a personal role in spearheading the effort along with New Mexico Democratic Sen. Martin Heinrich and Republican Sens. Mike Rounds of South Dakota and Todd Young of Indiana. “This roadmap represents the most comprehensive and impactful bipartisan recommendations on artificial intelligence ever issued by the legislative branch,” Young said Wednesday. The latest plan highlights how Senate leaders are trying to move from a learning phase to an action phase, by issuing assignments to committees to craft legislation that may be passed piecemeal. Schumer has previously said that with the 2024 elections fast approaching, he may make it a top priority to pass legislation aimed at protecting the elections from AI-driven interference. Schumer has described regulating artificial intelligence as a challenge for Congress unlike any other, vowing a swift timeline measured in months, not years. But policy analysts, and some congressional aides, doubt whether Congress can pass significant legislation regulating AI in an election year. Meanwhile, the European Union has surged ahead with AI regulation, giving final approval in March to the trading bloc’s landmark EU AI",0.17299999296665192,6.196000099182129
20240515,cnn,"News publishers sound alarm on Google’s new AI-infused search, warn of ‘catastrophic’ impacts","Editor’s Note: A version of this article first appeared in the “Reliable Sources” newsletter. Sign up for the daily digest chronicling the evolving media landscape here. The A.I. doomsday clock appears ready to strike midnight for publishers. Google on Tuesday announced that it will infuse its ubiquitous search engine with its powerful artificial intelligence model, Gemini, drawing on the rapidly advancing technology to directly answer user queries at the top of results pages. “Google will do the Googling for you,” the company explained. In other words, users will soon no longer have to click on the links displayed in search results to find the information they are seeking. On its surface that might sound convenient, but for news publishers — many of whom are already struggling with steep traffic declines — the revamped search experience will likely cause an even further decrease in audience, potentially starving them of readers and revenue. Why spend time clicking on a link when Google has already scoured the internet and harvested the relevant information with its A.I.? “Google will take care of the legwork,” executives said. But a lot of that legwork, of course, comes in the form of human-written articles and expertise published across the internet on blogs and media outlets, all built on a foundation of advertising support. Google’s message was heard loud and clear. Within hours of the Mountain View announcement, the news industry began sounding the alarm. “This will be catastrophic to our traffic, as marketed by Google to further satisfy user queries, leaving even less incentive to click through so that we can monetize our content,” Danielle Coffey, the chief executive of the News/Media Alliance, bluntly told CNN. Coffey, whose organization represents more than 2,000 news publishers and has taken an aggressive posture toward A.I. developers’ use of journalism, added: “The little traffic we get today will be further diminished, and with a dominant search engine that’s cementing its market power, we once again have to adhere to their terms. This time with a product that directly competes with our content, using our content to fuel it. This is a perverse twist on ‘innovation.’” The announcement from Google, which newsrooms had expected and expressed worry over in both public and private forums in recent months, is poised to further batter an industry that has been dealt a series of brutal blows — much of it at the hands of Big Tech — over the last several years. It also comes as OpenAI reportedly readies to launch its own A.I.-powered search engine. Since ChatGPT crashed onto the scene more than a year ago, showcasing the potential power of A.I. for the public and setting off an arms race with Google, Meta and others, publishers have worried greatly about the impact the technology will ultimately have on their businesses. But they have had little time to plan their responses to the transformative technology, given the breakneck pace in which it has developed. Some newsrooms have chosen to cautiously lock arms",-0.2529999911785126,14.4350004196167
20240517,nbcnews,Google's scam detection AI phone tests alarm privacy advocates ,"Some privacy advocates say they’re terrified by Google’s announcement this week that it’s testing a way to scan people’s phone calls in real time for signs of financial scams. Google unveiled the idea Tuesday at Google I/O, its conference for software developers. Dave Burke, a Google vice president for engineering, said the company is trying out a feature that uses artificial intelligence to detect patterns associated with scams and then alert Android phone users when suspected scams are in progress. Burke described the idea as a security feature and provided an example. Onstage, he got a demonstration call from someone impersonating a bank who suggested that he move his savings to a new account to keep it safe. Burke’s phone flashed a notification: “Likely scam: Banks will never ask you to move your money to keep it safe,” with an option to end the call. “Gemini Nano alerts me the second it detects suspicious activity,” Burke said, using the name of a Google-developed AI model. He didn’t specify what signals the software uses to determine a conversation is suspicious. The demonstration drew applause from the conference’s in-person audience in Mountain View, California, but some privacy advocates said the idea threatened to open a Pandora’s box as tech companies race to one-up one another on AI-enabled features for consumers. In interviews and in statements online, they said there were numerous ways the software could be abused by private surveillance companies, government agents, stalkers or others who might want to eavesdrop on other people’s phone calls. Burke said onstage that the feature wouldn’t transfer data off phones, providing what he said was a layer of potential protection “so the audio processing stays completely private.” But privacy advocates said on-device processing could still be vulnerable to intrusion by determined hackers, acquaintances with access to phones or government officials with subpoenas demanding audio files or transcripts. Burke didn’t say what kind of security controls Google would have, and Google didn’t respond to requests for additional information. “J. Edgar Hoover would be jealous,” said Albert Fox Cahn, executive director of the Surveillance Technology Oversight Project, an advocacy group based in New York. Hoover, who died in 1972, was director of the FBI for decades and used wiretaps extensively, including on civil rights figures. Cahn said the implications of Google’s idea were “terrifying,” especially for vulnerable people such as political dissidents or people seeking abortions. “The phone calls we make on our devices can be one of the most private things we do,” he said. “It’s very easy for advertisers to scrape every search we make, every URL we click, but what we actually say on our devices, into the microphone, historically hasn’t been monitored,” he said. It’s not clear when or whether Google would implement the idea. Burke said onstage that the company would have more to say in the summer. Tech companies frequently test ideas they never release to the public. Google has wide reach in the mobile phone market because it’s behind",-0.2590000033378601,9.973999977111816
20240517,foxnews,How artificial intelligence is reshaping modern warfare,"Modern warfare is changing rapidly, and harnessing artificial intelligence is key to staying ahead of America’s adversaries.&nbsp; Software companies including Govini&nbsp;and Palantir&nbsp;are behind the production and modernization of today's most high-tech weapon systems. Both companies were at the second annual AI Expo for National Competitiveness in Washington to showcase their work to the nation’s top military brass. Fox News saw first-hand this cutting-edge technology and had an exclusive interview with Palantir's CEO and co-founder Alex Karp, whose software is being used in Ukraine and the Middle East. ""The way to prevent a war with China is to ramp up not just Palantir, but defense tech startups that produce software-defining weapons systems that scare the living F out of our adversaries,"" Karp said. Karp emphasized either the U.S. will win the race for AI, or Russia and China will. FREAK ROBOT MADE IN CHINA CAN LEARN, THINK, WORK LIKE HUMANS Fear that AI could lead to killer robots and take humans out of the so-called ""kill chain"" has led to anxiety and threats of regulation that worries American innovators. But the U.S. has been ahead of its adversaries in artificial intelligence, and Karp said he wanted to keep it that way to deter any wrongdoing. ""Our adversaries have a long tradition of being not interested in the rule of law, not interested in fairness, not interested in human rights and on the battlefield. It really is going to be us or them. …&nbsp;You do not want a world order where our adversaries try to define new norms. It would be very bad for the world, and it would be especially bad for America,"" Karp explained. Fox News had the opportunity to look at some of the latest cutting-edge technology. Mixed Reality Command and Control goggles allow the war fighter to see the battlefield, available air assets, enemy targets and supply routes in 3D. Former intelligence analyst Shannon Clark, who has since led research and development for Palantir, said this targeting technology would have helped shorten the wars in Iraq and Afghanistan, possibly leading to different outcomes. Clark guided Fox News through four different demonstrations showing how the different technology worked and how U.S. generals could use it to make critical decisions in real time. WHAT IS ARTIFICIAL INTELLIGENCE (AI)? ""It's about speed. What was able to be done in days or weeks is now done in minutes,"" Clark said. As drone swarms have become more prominent in modern warfare, knowing exactly what weapons the U.S. had in its stockpiles would be critical to defending U.S. interests across the globe. &nbsp; ""I had a general say to me the other day, 'It doesn't matter if I have 50 targets. I need to know what ammo I have available,'"" Clark said. Maverick is an AI-generated target effector. Clark explained how it worked: ""Here's your list of targets. Here's the priority with which you want to action those targets. And, then, here's the effect that you should use in order to take action",0.0689999982714653,12.105999946594238
20240506,foxnews,"US will fall behind in AI race without onshoring chip production: 'Can't just design,' expert says","The United States will suffer in the race to command the development of artificial intelligence (AI) if production and manufacture of semiconductor chips and processors remain offshore, according to an industry expert.&nbsp; ""If you're not making things and all you're doing is designing the software, and maybe designing the chips, but they're completely built and packaged elsewhere, you don't end up innovating as much,"" Jonathan Klamkin, CEO of semiconductor company Aeluma, told Fox News Digital. ""When you literally have people's hands making some of these technologies, you innovate across the supply chain."" ""You'll innovate the manufacturing equipment that's used in the fabs, you'll innovate how to operate the fabs, you'll innovate the design of the chips,"" Klamkin said. ""The U.S. needs to be vertically integrated in semiconductors. We can't just design the chips and write the software code."" The U.S. faces competition from rival nations for the possession of the kinds of chips necessary to power the research and development of AI models. The demand for semiconductor chips and microprocessors skyrocketed along with mainstream interest in AI models and platforms.&nbsp; OPINION: DON'T USE SCIENCE FICTION TO INSPIRE PUBLIC POLICY ON AI Chip manufacturer&nbsp;Nvidia’s revenue rose 206%&nbsp;over the prior year in its latest quarter thanks to the surge in AI interest and demand.&nbsp; The Semiconductor Industry Association (SIA) has forecast a 13.1% jump in global chip sales to $595.3 billion this year, compared with a drop of about 8% in sales in 2023. The United Kingdom, for example, pledged to spend hundreds of millions of pounds on purchasing chips to allow researchers and developers to pursue breakthroughs and remain at the cutting edge of the industry as nations jockey for a leading role in AI. SOCIAL MEDIA PLATFORM CRACKS DOWN ON ADS FOR ‘AI GIRLFRIENDS’ The tightening supply with the high demand has pushed countries to seek out simpler chips to make up for the lack of more advanced chips and a stockpiling effort between companies.&nbsp; Gregory C. Allen, the director of the Wadhwani Center for AI and Advanced Technologies at the Center for Strategic and International Studies, previously told Fox News Digital that AI ""is the hottest category in global venture capital markets and technology investment."" ""Many different companies are being created to pursue AI technology, and so many major technology giants are remaking themselves around AI technology, especially after the more recent breakthroughs in generative AI and foundation models,"" Allen said.&nbsp; Part of the problem comes from the fact that the U.S. does not produce much of the global supply of chips. As of the passage of the CHIPS Act in 2022, the U.S. produced 12% of the advanced chips, compared to 37% in the 1990s; Taiwan produces the vast majority of advanced chips while China seeks to rapidly expand its manufacturing capabilities. WHAT IS ARTIFICIAL INTELLIGENCE (AI)? ""I'm not saying we need to make 100% of those chips, but maybe the number should be 30 or 40%,"" Klamkin said. ""So, that's what the CHIPS Act is doing,",-0.03700000047683716,6.706999778747559
20240506,cnn,Warren Buffett compares AI to nuclear weapons in stark warning,"Warren Buffett is worried about artificial intelligence. At his annual shareholder meeting in Omaha, Nebraska, the 93 year-old co-founder, chairman and CEO of Berkshire Hathaway issued a stark warning about the potential dangers of the technology. “We let a genie out of the bottle when we developed nuclear weapons,” he said Saturday. “AI is somewhat similar — it’s part way out of the bottle.” The so-called Oracle of Omaha acknowledged to his audience that he has little idea about the tech behind AI, but said he still fears its potential repercussions. His image and voice were recently replicated by an AI-backed tool, he said, and they were so convincing that they could have fooled his own family. Scams using these deep fakes, he added, will likely become increasingly prevalent. “If I was interested in investing in scamming, it’s going to be the growth industry of all time,” he told the crowd. Berkshire Hathaway has started employing some AI in its own business to make employees more efficient, said Greg Abel, the expected successor to Buffett who runs Berkshire’s non-insurance operations, on Saturday. “At times it displaces the labor, but then hopefully, there’s other opportunities,” said Abel, who didn’t reveal much detail about how the company plans to use AI. Buffett also acknowledged that the technology could change the world for the better, but said he isn’t sold yet. “It has enormous potential for good and enormous potential for harm,” he said. “And I just don’t know how that plays out.” The AI explosion has already transformed workplaces across the world and nearly 40% of global employment could be disrupted by AI, according to the International Monetary Fund. Industries from medicine to finance to music have already felt its effects. Shares of companies associated with the AI boom have soared. Chipmaker Nvidia (NVDA) is up about 215% over the last 12 months, while Microsoft (MSFT) is up about 34%. Shares of Berkshire Hathaway (BRK.A), have increased by 22% over the same period. Not just Buffett Buffett isn’t the only major business figure expressing concern about AI scamming. JPMorgan Chase CEO Jamie Dimon said in his annual shareholder letter last month that while he doesn’t yet know the full effect AI will have on business, the economy or society, he knows its influence will be significant. “We are completely convinced the consequences will be extraordinary and possibly as transformational as some of the major technological inventions of the past several hundred years: Think the printing press, the steam engine, electricity, computing and the Internet, among others,” the JPMorgan Chase (JPM) CEO wrote in the letter. Dimon also recognized the risks that come with the AI boom. “You may already be aware that there are bad actors using AI to try to infiltrate companies’ systems to steal money and intellectual property or simply to cause disruption and damage,” he wrote. In January, JPMorgan Chase said it had seen a sizable increase in daily attempts by hackers to infiltrate its systems over the",-0.2750000059604645,14.569000244140625
